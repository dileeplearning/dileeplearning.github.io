<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.7.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Dileep George">

  
  
  
    
  
  <meta name="description" content="AGI Research at DeepMind">

  
  <link rel="alternate" hreflang="en-us" href="/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Dileep George">
  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="/">

  
  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Dileep George">
  <meta property="og:url" content="/">
  <meta property="og:title" content="Dileep George">
  <meta property="og:description" content="AGI Research at DeepMind"><meta property="og:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png">
  <meta property="twitter:image" content="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png"><meta property="og:locale" content="en-us">
  
    <meta property="og:updated_time" content="2030-06-01T13:00:00&#43;00:00">
  

  

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "WebSite",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "/?q={search_term_string}",
    "query-input": "required name=search_term_string"
  },
  "url": "/"
}
</script>


  


  


  





  <title>Dileep George</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#navbar-main" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  

<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Dileep George</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Dileep George</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/research_landing_page/"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/publication/"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/comics_landing_page/"><span>AGI Comics</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/tweets/"><span>Tweets</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/talks_landing_page/"><span>Talks</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      <li class="nav-item">
        <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
      </li>
      

      

    </ul>

  </div>
</nav>


  











<span class="js-widget-page d-none"></span>




  







  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="about" class="home-section wg-about   "  >
    <div class="container">
      




  









<div class="row">
  <div class="col-12 col-lg-4">
    <div id="profile">

      
      
      <img class="portrait" src="/authors/admin/avatar_hua0e96dde60b2ddff52f4eca1263b9dcf_1231173_250x250_fill_q90_lanczos_center.jpg" alt="Avatar">
      

      <div class="portrait-title">
        <h2>Dileep George</h2>
        <h3>AGI Research at DeepMind</h3>

        
        <h3>
          
          <span>Entrepreneur, Scientist, and Engineer</span>
          
        </h3>
        
        <h3>
          
          <span>Previously Co-founder &amp; CTO at Vicarious AI</span>
          
        </h3>
        
      </div>

      <ul class="network-icon" aria-hidden="true">
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="/#contact" >
            <i class="fas fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        
        
          
        
        
        
        
        
          
        
        <li>
          <a href="https://twitter.com/dileeplearning" target="_blank" rel="noopener">
            <i class="fab fa-twitter big-icon"></i>
          </a>
        </li>
        
        
        
        
        
        
        
        
          
        
        <li>
          <a href="https://scholar.google.com/citations?user=0hmE5AUAAAAJ&amp;hl=en" target="_blank" rel="noopener">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-12 col-lg-8">

    
    

    <p>I am an engineer, scientist, and entrepreneur working on AI, neuroscience, and robotics. My goals are to understand how the brain works and to build Artificial General Intelligence (AGI). I'm now at DeepMind via acquisition of Vicarious.</p>
<p>I like building teams to pursue challenging goals. I co-founded two companies &ndash; <a href="www.vicarious.com">Vicarious AI</a> &amp; <a href="www.numenta.com">Numenta</a>. Vicarious was recently <a href="https://techcrunch.com/2022/04/22/alphabet-owned-intrinsic-is-acquiring-fellow-robotic-software-firm-vicarious/">acquired by Alphabet</a>: our AI+robotics business merged with <a href="www.intrinsic.ai">Intrinsic</a>, an Alphabet company, and our research team joined DeepMind to accelerate progress toward AGI.</p>
<p>Check out my works on <a href="https://www.biorxiv.org/content/10.1101/2020.09.09.290601v1">a detailed theoretical model for thalamic and cortical microcorcuits</a>, and <a href="https://www.youtube.com/watch?v=nrKbuCv_FuI">place cells as sequence learners</a> for examples of recent progress on understanding the brain.</p>
<p>I did my PhD at Stanford University with <a href="https://en.wikipedia.org/wiki/Bernard_Widrow">Dr. Bernard Widrow</a>, a pioneer of neural networks, and co-inventor of LMS gradient descent. During my PhD, I co-founded <a href="www.numenta.com">Numenta</a> with <a href="https://en.wikipedia.org/wiki/Jeff_Hawkins">Jeff Hawkins</a> and <a href="https://en.wikipedia.org/wiki/Donna_Dubinsky">Donna Dubinsky</a>, and co-developed the ideas behind <a href="uploads/HTM.pdf">Hierarchical Temporal Memory</a>.</p>


    <div class="row">

      
      <div class="col-md-5">
        <h3>Interests</h3>
        <ul class="ul-interests">
          
          <li>Artificial Intelligence</li>
          
          <li>Neuroscience and cognitive science</li>
          
          <li>Robotics</li>
          
          <li>Entreprenuership</li>
          
        </ul>
      </div>
      

      
      <div class="col-md-7">
        <h3>Education</h3>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">PhD in Electrical Engineering</p>
              <p class="institution">Stanford University</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">MS in Electrical Engineering</p>
              <p class="institution">Stanford University</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fas fa-graduation-cap"></i>
            <div class="description">
              <p class="course">BTech in Electrical Engineering</p>
              <p class="institution">IIT Bombay</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>

    </div>
  </section>

  
  
  

  

  

  

  

  

  
  

  
  
  

  
  
  
  
  

  
  

  <section id="featured" class="home-section wg-featured   "  >
    <div class="container">
      























<div class="row">
  <div class="col-12 col-lg-4 section-heading">
    <h1>Featured Publications</h1>
    
  </div>
  <div class="col-12 col-lg-8">

    

    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/rajkumar-vasudeva-raju/">Rajkumar Vasudeva Raju</a></span>, <span>J. Swaroop Guntupalli</span>, <span><a href="/authors/guangyao-zhou/">Guangyao Zhou</a></span>, <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December 2022
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      arXiv 2022
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/space-latent-sequence/">
      <img src="/publication/space-latent-sequence/featured_hu956062ea7f0e621181c6cfae4126f57d_600979_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/space-latent-sequence/">Space is a latent sequence: Structured sequence learning as a unified theory of representation in the hippocampus</a>
  </h3>

  
  <div class="article-style">
    <p>Fascinating and puzzling phenomena, such as landmark vector cells, splitter cells, and event-specific representations to name a few, are regularly discovered in the hippocampus. Without a unifying princi- ple that can explain these divergent observations, each experiment seemingly discovers a new anomaly or coding type. Here, we provide a unifying principle that the mental representation of space is an emergent property of latent higher-order sequence learning. Treating space as a sequence resolves myriad phenomena, and suggests that the place-field mapping methodology where sequential neuron responses are interpreted in spatial and Euclidean terms might itself be a source of anomalies. Our model, called Clone-structured Causal Graph (CSCG), uses a specific higher-order graph scaffolding to learn latent representations by mapping sensory inputs to unique contexts. Learning to compress sequential and episodic experiences using CSCGs result in the emergence of cognitive maps - mental representations of spatial and conceptual relationships in an environment that are suited for planning, introspection, consolidation, and abstraction. We demonstrate that over a dozen different hippocampal phenomena, ranging from those reported in classic experiments to the most recent ones, are succinctly and mechanistically explained by our model.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/2212.01508" target="_blank" rel="noopener">
    
    arXiv
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Dileep George</a></span>, <span>Rajeev V. Rikye,</span>, <span><a href="/authors/nishad-gothoskar/">Nishad Gothoskar,</a></span>, <span>J. Swaroop Guntupalli,</span>, <span><a href="/authors/antoine-dedieu/">Antoine Dedieu,</a></span>, <span>Miguel Lázaro-Gredilla</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    April 2021
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Biorxiv Preprint
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/cogmaps-natcomm/">
      <img src="/publication/cogmaps-natcomm/featured_hubcee71e6c77e2f638321a4549dcad3a9_808394_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/cogmaps-natcomm/">Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps</a>
  </h3>

  
  <div class="article-style">
    <p>Cognitive maps are mental representations of spatial and conceptual relationships in an environment, and are critical for flexible behavior. To form these abstract maps, the hippocampus has to learn to separate or merge aliased observations appropriately in different contexts in a manner that enables generalization and efficient planning. Here we propose a specific higher-order graph structure, clone-structured cognitive graph (CSCG), which forms clones of an observation for different contexts as a representation that addresses these problems. CSCGs can be learned efficiently using a probabilistic sequence model that is inherently robust to uncertainty. We show that CSCGs can explain a variety of cognitive map phenomena such as discovering spatial relations from aliased sensations, transitive inference between disjoint episodes, and formation of transferable schemas. Learning different clones for different contexts explains the emergence of splitter cells observed in maze navigation and event-specific responses in lap-running experiments. Moreover, learning and inference dynamics of CSCGs offer a coherent explanation for disparate place cell remapping phenomena. By lifting aliased observations into a hidden space, CSCGs reveal latent modularity useful for hierarchical abstraction and planning. Altogether, CSCG provides a simple unifying framework for understanding hippocampal function, and could be a pathway for forming relational abstractions in artificial intelligence.</p>
  </div>
  

  
  <div class="btn-links">
    








  









  
    
  









<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://doi.org/https://doi.org/10.1038/s41467-021-22559-5" target="_blank" rel="noopener">
  DOI
</a>


  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.nature.com/articles/s41467-021-22559-5" target="_blank" rel="noopener">
    
    Nature Communications (2021)
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Dileep George</a></span>, <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>, <span><a href="/authors/wolfgang-lehrach/">Wolfgang Lehrach</a></span>, <span><a href="/authors/antoine-dedieu/">Antoine Dedieu</a></span>, <span><a href="/authors/guangyao-zhou/">Guangyao Zhou</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Biorxiv Preprint
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/cortical-microcircuits/">
      <img src="/publication/cortical-microcircuits/featured_hue5b6509a659c1dbcba3932f2a7f4e428_628505_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/cortical-microcircuits/">A detailed mathematical theory of thalamic and cortical microcircuits based on inference in a generative vision model</a>
  </h3>

  
  <div class="article-style">
    <p>Understanding the information processing roles of cortical circuits is an outstanding problem in neuroscience and artificial intelligence. Theory-driven efforts will be required to tease apart the functional logic of cortical circuits from the vast amounts of experimental data on cortical connectivity and physiology. Although the theoretical setting of Bayesian inference has been suggested as a framework for understanding cortical computation, making precise and falsifiable biological mappings need models that tackle the challenge of real world tasks. Based on a recent generative model, Recursive Cortical Networks, that demonstrated excellent performance on visual task benchmarks, we derive a family of anatomically instantiated and functional cortical circuit models. Efficient inference and generalization guided the representational choices in the original computational model. The cortical circuit model is derived by systematically comparing the computational requirements of this model with known anatomical constraints. The derived model suggests precise functional roles for the feed-forward, feedback, and lateral connections observed in different laminae and columns, assigns a computational role for the path through the thalamus, predicts the interactions between blobs and inter-blobs, and offers an algorithmic explanation for the innate inter-laminar connectivity between clonal neurons within a cortical column. The model also explains several visual phenomena, including the subjective contour effect, and neon-color spreading effect, with circuit-level precision. Our work paves a new path forward in understanding the logic of cortical and thalamic circuits.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://doi.org/10.1101/2020.09.09.290601" target="_blank" rel="noopener">
    
    Biorxiv Preprint (2020)
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span>Daniel P. Sawyer</span>, <span>Miguel Lázaro-Gredilla</span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    February 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Cognitive Science
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/fast-cognitive-programs/">
      <img src="/publication/fast-cognitive-programs/featured_huf44fcde2c265119c697368c1d82c6f2d_138846_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/fast-cognitive-programs/">A Model of Fast Concept Inference with Object-Factorized Cognitive Programs</a>
  </h3>

  
  <div class="article-style">
    <p>The ability of humans to quickly identify general concepts from a handful of images has proven difficult to emulate with robots. Recently, a computer architecture was developed that allows robots to mimic some aspects of this human ability by modeling concepts as cognitive programs using an instruction set of primitive cognitive functions. This allowed a robot to emulate human imagination by simulating candidate programs in a world model before generalizing to the physical world. However, this model used a naive search algorithm that required 30 minutes to discover a single concept, and became intractable for programs with more than 20 instructions. To circumvent this bottleneck, we present an algorithm that emulates the human cognitive heuristics of object factorization and sub-goaling, allowing human-level inference speed, improving accuracy, and making the output more explainable.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2002.04021.pdf" target="_blank" rel="noopener">
    
    Cognitive Science 2020
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span>Rajeev V. Rikye,</span>, <span><a href="/authors/nishad-gothoskar/">Nishad Gothoskar,</a></span>, <span>J. Swaroop Guntupalli,</span>, <span><a href="/authors/antoine-dedieu/">Antoine Dedieu,</a></span>, <span>Miguel Lázaro-Gredilla</span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2020
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Biorxiv Preprint
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/cognitive-maps-biorxiv/">
      <img src="/publication/cognitive-maps-biorxiv/featured_hu77e4ad8001d6722cd19ca8e14462351c_47548_918x517_fill_q90_lanczos_smart1.jpg" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/cognitive-maps-biorxiv/">Learning cognitive maps as structured graphs for vicarious evaluation</a>
  </h3>

  
  <div class="article-style">
    <p>Cognitive maps enable us to learn the layout of environments, encode and retrieve episodic memories, and navigate vicariously for mental evaluation of options. A unifying model of cognitive maps will need to explain how the maps can be learned scalably with sensory observations that are non-unique over multiple spatial locations (aliased), retrieved efficiently in the face of uncertainty, and form the fabric of efficient hierarchical planning. We propose learning higher-order graphs – structured in a specific way that allows efficient learning, hierarchy formation, and inference – as the general principle that connects these different desiderata. We show that these graphs can be learned efficiently from experienced sequences using a cloned Hidden Markov Model (CHMM), and uncertainty-aware planning can be achieved using message-passing inference. Using diverse experimental settings, we show that CHMMs can be used to explain the emergence of context-specific representations, formation of transferable structural knowledge, transitive inference, shortcut finding in novel spaces, remapping of place cells, and hierarchical planning. Structured higher-order graph learning and probabilistic inference might provide a simple unifying framework for understanding hippocampal function, and a pathway for relational abstractions in artificial intelligence.</p>
  </div>
  

  
  <div class="btn-links">
    








  









  
    
  










  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.biorxiv.org/content/10.1101/864421v4" target="_blank" rel="noopener">
    
    Biorxiv Preprint (2020)
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>, <span><a href="/authors/wolfgang-lehrach/">Wolfgang Lehrach</a></span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Advances in approximate Bayesian inference &ndash; 2019.
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/bayesian-qt/">
      <img src="/publication/bayesian-qt/featured_hu04e1b00e9f3b0f0f1770c521a7264d4b_81903_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/bayesian-qt/">Learning undirected models via query training</a>
  </h3>

  
  <div class="article-style">
    <p>Query training is a a technique that lets you train graphical models using ideas from deep learning.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1912.02893" target="_blank" rel="noopener">
    
    2019 Approximate Bayesian Inference Workshop
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/nishad-gothoskar/">Nishad Gothoskar</a></span>, <span>J. Swaroop Guntupalli</span>, <span><a href="/authors/rajeev-rikhye/">Rajeev Rikhye</a></span>, <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Cognitive Computational Neuroscience
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/ccn-different-clones/">
      <img src="/publication/ccn-different-clones/featured_huc9cfcf62ba2be0de6cbeed9d216f3fa2_142459_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/ccn-different-clones/">Different clones for different contexts: Hippocampal cognitive maps as higher-order graphs of a cloned HMM</a>
  </h3>

  
  <div class="article-style">
    <p>Hippocampus encodes cognitive maps that support episodic memories, navigation, and planning. Under-standing the commonality among those maps as well as how those maps are structured, learned from experience, and used for inference and planning is an interesting but unsolved problem. We propose higher-order graphs as the general principle and present, as a plausible model, a cloned hidden Markov model (HMM) that can learn these graphs efficiently from experienced sequences. In our experiments, we use the cloned HMM for learning spatial and abstract representations. We show that inference and planning in the learned CHMM encapsulates many of the key properties of hippocampal cells observed in rodents and humans. Cloned HMM thus provides a new frame-work for understanding hippocampal function.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.biorxiv.org/content/10.1101/745950v1" target="_blank" rel="noopener">
    
    2019 Cognitive Computatational Neuroscience
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/rajeev-rikhye/">Rajeev Rikhye</a></span>, <span><a href="/authors/nishad-gothoskar/">Nishad Gothoskar</a></span>, <span>J. Swaroop Guntupalli</span>, <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Cognitive Computational Neuroscience
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/ccn-memorize-generalize/">
      <img src="/publication/ccn-memorize-generalize/featured_hu8f7afce98710d6ba7e2f3135b39a61c5_135852_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/ccn-memorize-generalize/">Memorize-Generalize: An online algorithm for learning higher-order sequential structure with cloned Hidden Markov Models</a>
  </h3>

  
  <div class="article-style">
    <p>Sequence learning is a vital cognitive function and has been observed in numerous brain areas. Discovering the algorithms underlying sequence learning has been a major endeavour in both neuroscience and machine learning. In earlier work we showed that by constraining the sparsity of the emission matrix of a Hidden Markov Model (HMM) in a biologically-plausible manner we are able to efficiently learn higher-order temporal dependencies and recognize contexts in noisy signals. The central basis of our model, referred to as the Cloned HMM (CHMM), is the observation that cortical neurons sharing the same receptive field properties can learn to represent unique incidences of bottom-up information within different temporal contexts. CHMMs can efficiently learn higher-order temporal dependencies, recognize long-range contexts and, unlike recurrent neural networks, are able to natively handle uncertainty. In this paper we introduce a biologically plausible CHMM learning algorithm, memorize-generalize, that can rapidly memorize sequences as they are encountered, and gradually generalize as more data is accumulated. We demonstrate that CHMMs trained with the memorize-generalize algorithm can model long-range structure in bird songs with only a slight degradation in performance compared to expectation-maximization, while still outperforming other representations.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.biorxiv.org/content/10.1101/764456v1" target="_blank" rel="noopener">
    
    2019 Cognitive Computatational Neuroscience
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/antoine-dedieu/">Antoine Dedieu∗†</a></span>, <span><a href="/authors/nishad-gothoskar/">Nishad Gothoskar∗†</a></span>, <span><a href="/authors/scott-swingle/">Scott Swingle</a></span>, <span><a href="/authors/wolfgang-lehrach/">Wolfgang Lehrach</a></span>, <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>, <span><a href="/authors/dileep-george/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    May 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Science
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/cloned-hmm/">
      <img src="/publication/cloned-hmm/featured_hu00b3ed71b849a31e39f56ae4338e2947_188542_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/cloned-hmm/">Learning higher-order sequential structure with cloned HMMs</a>
  </h3>

  
  <div class="article-style">
    <p>Variable order sequence modeling is an important problem in artificial and natural intelligence. While overcomplete Hidden Markov Models (HMMs), in theory, have the capacity to represent long-term tem- poral structure, they often fail to learn and converge to local minima. We show that by constraining HMMs with a simple sparsity structure inspired by biology, we can make it learn variable order sequences efficiently. We call this model cloned HMM (CHMM) because the sparsity structure enforces that many hidden states map deterministically to the same emission state. CHMMs with over 1 billion parameters can be efficiently trained on GPUs without being severely affected by the credit diffusion problem of standard HMMs. Unlike n-grams and sequence memoizers, CHMMs can model temporal dependencies at arbitrarily long distances and recognize contexts with “holes” in them. Compared to Recurrent Neural Networks and their Long Short-Term Memory extensions (LSTMs), CHMMs are generative models that can natively deal with uncertainty. Moreover, CHMMs return a higher-order graph that represents the temporal structure of the data which can be useful for community detection, and for building hierarchical models. Our experiments show that CHMMs can beat n-grams, sequence memoizers, and LSTMs on character-level language modeling tasks. CHMMs can be a viable alternative to these methods in some tasks that require variable order sequence modeling and the handling of uncertainty.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1905.00507" target="_blank" rel="noopener">
    
    Arxiv 2019
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>, <span><a href="/authors/dianhuan-lian/">Dianhuan Lian</a></span>, <span>J. Swaroop Guntupalli</span>, <span><a href="/authors/dileep-george/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    February 2019
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Science Robotics
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/cognitive-programs/">
      <img src="/publication/cognitive-programs/featured_huadde8a2d0ba7585cb81366c0323ee431_546988_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/cognitive-programs/">Beyond Imitation: Zero-shot task transfer on robots by learning concepts as cognitive programs</a>
  </h3>

  
  <div class="article-style">
    <p>Concepts are formalized as programs on a special computer architectrue called the Visual Cognitive Computer (VCC). By learning programs on VCC, concepts transfer from schematic inputs to real-wrold robots.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="http://robotics.sciencemag.org/cgi/content/full/4/26/eaav3150?ijkey=9p/p9D23WW2Ek&amp;keytype=ref&amp;siteid=robotics" target="_blank" rel="noopener">
    
    Science Robotics. Open Access (2019)
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.sciencemag.org/news/2019/01/robots-people-use-imagination-learn-concepts" target="_blank" rel="noopener">
    
    Science Magazine Video
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.vicarious.com/2019/01/18/a-thought-is-a-program/" target="_blank" rel="noopener">
    
    Vicarious Blog: A thought is a program
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/vicariousinc/science_cognitive_programs" target="_blank" rel="noopener">
    
    Code: Learning abstractions
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/vicariousinc/science_cognitive_programs" target="_blank" rel="noopener">
    
    Dataset: Tabletop visual cognitive concepts
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://fortune.com/2019/01/17/robot-human-concept-learning-ikea-furniture/" target="_blank" rel="noopener">
    
    Press: Fortune magazine
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://techcrunch.com/2019/01/16/robots-learn-to-grab-and-scramble-with-new-levels-of-agility/" target="_blank" rel="noopener">
    
    Press: TechCrunch
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.sciencenews.org/article/new-robots-follow-instructions-diagrams-pictures" target="_blank" rel="noopener">
    
    Press: ScienceNews
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Dileep George</a></span>, <span><a href="/authors/wolfgang-lehrach/">Wolfgang Lehrach</a></span>, <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Cognitive Computational Neuroscience
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/cortical-circuits-ccn/">
      <img src="/publication/cortical-circuits-ccn/featured_hu1a3c8519be3b961f306d23d3cb2daa41_63793_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/cortical-circuits-ccn/">Cortical micro-circuits from a generative vision model</a>
  </h3>

  
  <div class="article-style">
    <p>A hierarchical vision model that emphasizes the role of lateral and feedback connections and treats classification, segmentation geneeration, and occlusion-reasoning in a unified framework.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/1808.01058.pdf" target="_blank" rel="noopener">
    
    Cognitive Computational Neuroscience 2018
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Dileep George</a></span>, <span><a href="/authors/wolfgang-lehrach/">Wolfgang Lehrach</a></span>, <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Cognitive Computational Neuroscience
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/cortical-phenom-ccn/">
      <img src="/publication/cortical-phenom-ccn/featured_hu1f03c9569f5dca6bada137240945e12c_306628_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/cortical-phenom-ccn/">Explaining Visual Cortex Phenomena using Recursive Cortical Network</a>
  </h3>

  
  <div class="article-style">
    <p>A hierarchical vision model that emphasizes the role of lateral and feedback connections and treats classification, segmentation geneeration, and occlusion-reasoning in a unified framework.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.biorxiv.org/content/10.1101/380048v1" target="_blank" rel="noopener">
    
    CCN 2018
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/nicholas-hay/">Nicholas Hay</a></span>, <span><a href="/authors/michael-stark/">Michael Stark</a></span>, <span><a href="/authors/alexander-schlegel/">Alexander Schlegel</a></span>, <span><a href="/authors/carter-wendelken/">Carter Wendelken</a></span>, <span><a href="/authors/dennis-park/">Dennis Park</a></span>, <span><a href="/authors/eric-purdy/">Eric Purdy</a></span>, <span><a href="/authors/tom-silver/">Tom Silver</a></span>, <span>D. Scott Phoenix</span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    February 2018
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      AAAI
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/smc-aaai/">
      <img src="/publication/smc-aaai/featured_hue5654f6c2059c053c178d91d5393bebd_186118_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/smc-aaai/">Behavior is Everything: Towards Representing Concepts with Sensorimotor Contingencies</a>
  </h3>

  
  <div class="article-style">
    <p>AI has seen remarkable progress in recent years, due to a switch from hand-designed shallow representations, to learned deep representations. While these methods excel with plentiful training data, they are still far from the human ability to learn concepts from just a few examples by reusing previously learned conceptual knowledge in new contexts. We argue that this gap might come from a fundamental misalignment between human and typical AI representations: while the former are grounded in rich sensorimotor expe- rience, the latter are typically passive and limited to a few modalities such as vision and text. We take a step towards closing this gap by proposing an interactive, behavior-based model that represents concepts using sensorimotor contingencies grounded in an agent’s experience. On a novel conceptual learning and benchmark suite, we demonstrate that conceptually meaningful behaviors can be learned, given supervision via training curricula.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://pdfs.semanticscholar.org/6fe3/38f8741c41e18f7efbe6767ca5b2b099ce6c.pdf" target="_blank" rel="noopener">
    
    AAAI 2018
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.vicarious.com/posts/learning-concepts-through-sensorimotor-interactions" target="_blank" rel="noopener">
    
    Vicarious Blog. From action to abstraction.
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Dileep George</a></span>, <span><a href="/authors/wolfgang-lehrach/">Wolfgang Lehrach</a></span>, <span><a href="/authors/ken-kansky/">Ken Kansky</a></span>, <span><a href="/authors/miguel-lazaro-gredilla/">Miguel Lazaro-Gredilla</a></span>, <span><a href="/authors/christopher-laan/">Christopher Laan</a></span>, <span><a href="/authors/bhaskara-marthi/">Bhaskara Marthi</a></span>, <span><a href="/authors/xinghua-lou/">Xinghua Lou</a></span>, <span><a href="/authors/zhaoshi-meng/">Zhaoshi Meng</a></span>, <span><a href="/authors/yi-liu/">Yi Liu</a></span>, <span><a href="/authors/huayan-wang/">Huayan Wang</a></span>, <span><a href="/authors/alex-lavin/">Alex Lavin</a></span>, <span>D. Scott Phoenix</span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    October 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Science
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/science-captcha/">
      <img src="/publication/science-captcha/featured_hu0ed68a1b04183979e0c84e043c587591_1028728_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/science-captcha/">A generative model for vision that trains with high data efficiency and breaks text-based CAPTCHAs</a>
  </h3>

  
  <div class="article-style">
    <p>Learning from a few examples and generalizing to markedly different situations are capabilities of human visual intelligence that are yet to be matched by leading machine learning models. By drawing inspiration from systems neuroscience, we introduce a probabilistic generative model for vision in which message-passing–based inference handles recognition, segmentation, and reasoning in a unified way. The model demonstrates excellent generalization and occlusion-reasoning capabilities and outperforms deep neural networks on a challenging scene text recognition benchmark while being 300-fold more data efficient. In addition, the model fundamentally breaks the defense of modern text-based CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) by generatively segmenting characters without CAPTCHA-specific heuristics. Our model emphasizes aspects such as data efficiency and compositionality that may be important in the path toward general artificial intelligence.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://science.sciencemag.org/content/358/6368/eaag2612" target="_blank" rel="noopener">
    
    Science: Open access (2017)
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.vicarious.com/2017/10/26/common-sense-cortex-and-captcha/" target="_blank" rel="noopener">
    
    Vicarious Blog: Commonsense, Cortex and CAPTCHA
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/vicariousinc/science_rcn%27" target="_blank" rel="noopener">
    
    Code/Github
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.bbc.com/news/technology-41775968" target="_blank" rel="noopener">
    
    BBC
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.npr.org/sections/thetwo-way/2017/10/26/560082659/ai-model-fundamentally-cracks-captchas-scientists-say?f=&amp;ft=nprml" target="_blank" rel="noopener">
    
    NPR
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.wired.co.uk/article/captcha-automation-broken-history-fix" target="_blank" rel="noopener">
    
    Wired
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/captcha-puzzles-recaptcha-solve-problems-vicarious-bots-artificial-intelligence-a8029401.html" target="_blank" rel="noopener">
    
    The Independent
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/ken-kansky/">Ken Kansky</a></span>, <span><a href="/authors/tom-silver/">Tom Silver</a></span>, <span>David A. Mély</span>, <span><a href="/authors/mohamed-eldawy/">Mohamed Eldawy,</a></span>, <span>Miguel Lázaro-Gredilla,</span>, <span><a href="/authors/xinghua-lou/">Xinghua Lou,</a></span>, <span><a href="/authors/nimrod-dorfman/">Nimrod Dorfman,</a></span>, <span><a href="/authors/szymon-sidor/">Szymon Sidor</a></span>, <span><a href="/authors/scott-phoenix/">Scott Phoenix</a></span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Science
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/schema-networks/">
      <img src="/publication/schema-networks/featured_hu823dcf9970cb277d7674216853df23f2_29293_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/schema-networks/">Schema Networks: Zero-shot transfer with a generative causal model of  intuitive physics</a>
  </h3>

  
  <div class="article-style">
    <p>The recent adaptation of deep neural network-based methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks. Nonetheless, progress on task-to-task transfer remains limited. In pursuit of efficient and robust generalization, we introduce the Schema Network, an object-oriented generative physics simulator capable of disentangling multiple causes of events and reasoning backward through causes to achieve goals. The richly structured architecture of the Schema Network can learn the dynamics of an environment directly from data. We compare Schema Networks with Asynchronous Advantage Actor-Critic and Progressive Networks on a suite of Breakout variations, reporting results on training efficiency and zero-shot generalization, consistently demonstrating faster, more robust learning and better transfer. We argue that generalizing from limited data and learning causal relationships are essential abilities on the path toward generally intelligent systems.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1706.04317" target="_blank" rel="noopener">
    
    ICML 2017
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.vicarious.com/posts/general-game-playing-with-schema-networks" target="_blank" rel="noopener">
    
    Vicarious Blog
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.wired.com/story/vicarious-schema-networks-artificial-intelligence-atari-demo/" target="_blank" rel="noopener">
    
    Press: Wired
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span>Miguel Lázaro-Gredilla</span>, <span><a href="/authors/yi-liu/">Yi Liu,</a></span>, <span>D. Scott Phoenix,</span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Arxiv
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/hcn-feature-learning/">
      <img src="/publication/hcn-feature-learning/featured_hu351d8cd910538fa69e6181cad0fae3d9_111929_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/hcn-feature-learning/">Hierarchical Compositional Feature Learning</a>
  </h3>

  
  <div class="article-style">
    <p>We introduce the hierarchical compositional network (HCN), a directed generative model able to discover and disentangle, without supervision, the building blocks of a set of binary images. The building blocks are binary features defined hierarchically as a composition of some of the features in the layer immediately below, arranged in a particular manner. At a high level, HCN is similar to a sigmoid belief network with pooling. Inference and learning in HCN are very challenging and existing variational approximations do not work satisfactorily. A main contribution of this work is to show that both can be addressed using max-product message passing (MPMP) with a particular schedule (no EM required). Also, using MPMP as an inference engine for HCN makes new tasks simple: adding supervision information, classifying images, or performing inpainting all correspond to clamping some variables of the model to their known values and running MPMP on the rest. When used for classification, fast inference with HCN has exactly the same functional form as a convolutional neural network (CNN) with linear activations and binary weights. However, HCN's features are qualitatively very different.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/1611.02252.pdf" target="_blank" rel="noopener">
    
    ArXiv 2017
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.vicarious.com/posts/toward-learning-a-compositional-visual-representation/" target="_blank" rel="noopener">
    
    Vicarious Blog
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/austin-stone/">Austin Stone</a></span>, <span><a href="/authors/huayan-wang/">Huayan Wang</a></span>, <span><a href="/authors/michael-stark/">Michael Stark</a></span>, <span><a href="/authors/yi-liu/">Yi Liu</a></span>, <span>D. Scott Phoenix</span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    June 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      CVPR 2017
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/teaching-compositionality/">
      <img src="/publication/teaching-compositionality/featured_hu6bd6f566c697ecb72bc83e3022846749_1819040_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/teaching-compositionality/">Teaching compositionality to CNNs</a>
  </h3>

  
  <div class="article-style">
    <p>Convolutional neural networks (CNNs) have shown great success in computer vision, approaching human-level performance when trained for specific tasks via application-specific loss functions. In this paper, we propose a method for augmenting and training CNNs so that their learned features are compositional. It encourages networks to form representations that disentangle objects from their surroundings and from each other, thereby promoting better generalization. Our method is agnostic to the specific details of the underlying CNN to which it is applied and can in principle be used with any CNN. As we show in our experiments, the learned representations lead to feature activations that are more localized and improve performance over non-compositional baselines in object recognition tasks.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1706.04313" target="_blank" rel="noopener">
    
    CVPR 2017
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.vicarious.com/posts/toward-learning-a-compositional-visual-representation/" target="_blank" rel="noopener">
    
    Vicarious Blog: Toward Learning a Compositional Visual Representation
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    January 2017
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Behavioral and Brain Sciences
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/bbs-article/">
      <img src="/publication/bbs-article/featured_huce19502a6a75ea89b3e75d665580d73c_322465_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/bbs-article/">What can the brain teach us about building artificial intelligence?</a>
  </h3>

  
  <div class="article-style">
    <p>This paper is an invited commentary on Lake et al's Behavioral and Brain Sciences article titled &ldquo;Building machines that learn and think like people&rdquo;. Lake et al's paper offers a timely critique on the recent accomplishments in artificial intelligence from the vantage point of human intelligence, and provides insightful suggestions about research directions for building more human-like intelligence. Since we agree with most of the points raised in that paper, we will offer a few points that are complementary</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/what-can-the-brain-teach-us-about-building-artificial-intelligence/4AAA6F9298B573B3B39B1E2D554D4669" target="_blank" rel="noopener">
    
    Behavioral and Brain Sciences (2017)
  </a>

  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/abs/1909.01561" target="_blank" rel="noopener">
    
    Arxiv version (2017)
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/xinghua-lou/">Xinghua Lou</a></span>, <span><a href="/authors/ken-kansky/">Ken Kansky</a></span>, <span><a href="/authors/wolfgang-lehrach/">Wolfgang Lehrach</a></span>, <span><a href="/authors/cc-laan/">CC Laan</a></span>, <span><a href="/authors/bhaskara-marthi/">Bhaskara Marthi</a></span>, <span>D. Scott Phoenix</span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    December 2016
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      NeurIPS
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/generative-shape/">
      <img src="/publication/generative-shape/featured_hud54f32275979d31399007206949d7e14_143840_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/generative-shape/">Generative shape models</a>
  </h3>

  
  <div class="article-style">
    <p>Learning from a few examples and generalizing to markedly different situations are capabilities of human visual intelligence that are yet to be matched by leading machine learning models. By drawing inspiration from systems neuroscience, we introduce a probabilistic generative model for vision in which message-passing–based inference handles recognition, segmentation, and reasoning in a unified way. The model demonstrates excellent generalization and occlusion-reasoning capabilities and outperforms deep neural networks on a challenging scene text recognition benchmark while being 300-fold more data efficient. In addition, the model fundamentally breaks the defense of modern text-based CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) by generatively segmenting characters without CAPTCHA-specific heuristics. Our model emphasizes aspects such as data efficiency and compositionality that may be important in the path toward general artificial intelligence.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://papers.nips.cc/paper/2016/file/23ad3e314e2a2b43b4c720507cec0723-Paper.pdf" target="_blank" rel="noopener">
    
    NeurIPS 2016
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Dileep George</a></span>, <span><a href="/authors/jeff-hawkins/">Jeff Hawkins</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2009
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      PLoS Computational Biology
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/plos-cortical-circuits/">
      <img src="/publication/plos-cortical-circuits/featured_hu0cdb67d6a2381c536987efbed9547e1d_1280138_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/plos-cortical-circuits/">Towards a Mathematical Theory of Cortical Micro-circuits</a>
  </h3>

  
  <div class="article-style">
    <p>The theoretical setting of hierarchical Bayesian inference is gaining acceptance as a framework for understanding cortical computation. In this paper, we describe how Bayesian belief propagation in a spatio-temporal hierarchical model, called Hierarchical Temporal Memory (HTM), can lead to a mathematical model for cortical circuits. An HTM node is abstracted using a coincidence detector and a mixture of Markov chains. Bayesian belief propagation equations for such an HTM node define a set of functional constraints for a neuronal implementation. Anatomical data provide a contrasting set of organizational constraints. The combination of these two constraints suggests a theoretically derived interpretation for many anatomical and physiological features and predicts several others. We describe the pattern recognition capabilities of HTM networks and demonstrate the application of the derived circuits for modeling the subjective contour effect. We also discuss how the theory and the circuit can be extended to explain cortical features that are not explained by the current model and describe testable predictions that can be derived from the model.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000532" target="_blank" rel="noopener">
    
    PLoS Computational Biology (2009)
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2008
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      PhD Thesis. Electrical Engineering. Stanford University
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/phd-thesis/">
      <img src="/publication/phd-thesis/featured_hue9eb0013ae5fd4918e34c1586aab1906_233643_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/phd-thesis/">How the brain might work: A hierarchical model of learning and recognition</a>
  </h3>

  
  <div class="article-style">
    <p><!-- 
<div class="alert alert-note">
  <div>
    Click the <em>Cite</em> button above to demo the feature to enable visitors to import publication metadata into their reference management software.
  </div>
</div>


<div class="alert alert-note">
  <div>
    Click the <em>Slides</em> button above to demo Academic's Markdown slides feature.
  </div>
</div>


Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -->
</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.163.7566&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">
    
    Stanford Univeristy PhD Thesis (2008)
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/jeff-hawkins/">Jeff Hawkins</a></span>, <span><a href="/authors/admin/">Dileep George</a></span>, <span><a href="/authors/jamie-niemasik/">Jamie Niemasik</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2008
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      Proceedings of the Royal Society B
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/royal_society_seq/">
      <img src="/publication/royal_society_seq/featured_hucf1d1888d1a09b80679386204cdef587_248623_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/royal_society_seq/">Sequence memory for prediction, inference and behaviour</a>
  </h3>

  
  <div class="article-style">
    <p>In this paper, we propose a mechanism which the neocortex may use to store sequences of patterns. Storing and recalling sequences are necessary for making predictions, recognizing time-based patterns and generating behaviour. Since these tasks are major functions of the neocortex, the ability to store and recall time-based sequences is probably a key attribute of many, if not all, cortical areas. Previously, we have proposed that the neocortex can be modelled as a hierarchy of memory regions, each of which learns and recalls sequences. This paper proposes how each region of neocortex might learn the sequences necessary for this theory. The basis of the proposal is that all the cells in a cortical column share bottom-up receptive field properties, but individual cells in a column learn to represent unique incidences of the bottom-up receptive field property within different sequences. We discuss the proposal, the biological constraints that led to it and some results modelling it.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://royalsocietypublishing.org/doi/abs/10.1098/rstb.2008.0322" target="_blank" rel="noopener">
    
    Phil Trans. Royal Society B (2008)
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/admin/">Dileep George</a></span>, <span><a href="/authors/jeff-hawkins/">Jeff Hawkins</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2005
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      International Joint Conference on Neural Networks
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/ijcnn-bayesian/">
      <img src="/publication/ijcnn-bayesian/featured_hua8c0c4d0c42f4572d8433bf8e804842f_57500_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/ijcnn-bayesian/">A Hierarchical Bayesian Model of Invariant Pattern Recognition in the Visual Cortex</a>
  </h3>

  
  <div class="article-style">
    <p>We describe a hierarchical model of invariant visual pattern recognition in the visual cortex. In this model, the knowledge of how patterns change when objects move is learned and encapsulated in terms of high probability sequences at each level of the hierarchy. Configuration of object parts is captured by the patterns of coincident high probability sequences. This knowledge is then encoded in a highly efficient Bayesian Network structure.The learning algorithm uses a temporal stability criterion to discover object concepts and movement patterns. We show that the architecture and algorithms are biologically plausible. The large scale architecture of the system matches the large scale organization of the cortex and the micro-circuits derived from the local computations match the anatomical data on cortical circuits. The system exhibits invariance across a wide variety of transformations and is robust in the presence of noise. Moreover, the model also offers alternative explanations for various known cortical phenomena.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="http://www.cnbc.cmu.edu/cns/papers/GeorgeHawkinsIJCNN05.pdf" target="_blank" rel="noopener">
    
    IJCNN 2005
  </a>


  </div>
  

</div>

      
    
      
        





  





  


<div class="card-simple">

  
    


<div class="article-metadata">

  
  
  
  
  <div>
    



  
  <span><a href="/authors/pat-langley/">Pat Langley</a></span>, <span><a href="/authors/admin/">Dileep George</a></span>

  </div>
  
  

  
  <span class="article-date">
    
    
      
    
    September 2003
  </span>
  

  
  <span class="middot-divider"></span>
  <span class="pub-publication">
    
      ICML
    
  </span>
  

  

  
  
  

  
  

</div>

  

  
  
  
  
  <a href="/publication/icml-process-induction/">
      <img src="/publication/icml-process-induction/featured_hu46e37fe88bbbb0089aa612c10beea3e8_99280_918x517_fill_q90_lanczos_smart1_2.png" class="article-banner" alt="">
  </a>
  

  <h3 class="article-title mb-1 mt-3">
    <a href="/publication/icml-process-induction/">Robust induction of process models from time-series data</a>
  </h3>

  
  <div class="article-style">
    <p>In this paper, we revisit the problem of in- ducing a process modelfrom time-series data. Weillustrate this task with a realistic ecosys- tem model, review an initial method for its induction, then identify three challenges that require extension of this method. These in- clude dealing with unobservable variables, finding numeric conditions on processes, and preventing the creation of models that over- fit the training data. Wedescribe responses to these challenges and present experimental evidence that they have the desired effects. After this, we show that this extended ap- proach to inductive process modeling can ex- plain and predict time-series data from bat- teries on the International Space Station. In closing, we discuss related work and consider directions for future research.</p>
  </div>
  

  
  <div class="btn-links">
    








  


















  
  
  
    
  
  
  
  
  
    
  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.aaai.org/Papers/ICML/2003/ICML03-058.pdf" target="_blank" rel="noopener">
    
    ICML 2003
  </a>


  </div>
  

</div>

      
    

  </div>
</div>

    </div>
  </section>



      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js" integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.a0d331bcd05dbe8b31e244f796710f08.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
