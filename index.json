[{"authors":["admin"],"categories":null,"content":"I am an engineer, scientist, and entrepreneur working at the intersection of artficial intelligence, neuroscience, and robotics. My long-term goal is to build human-level intelligence based on the principles we learn from cognitive science and neuroscience. To this end, I co-founded Vicarious AI with Scott Phoenix. Check out our projects at www.vicarious.com\nIn addition to building intelligent machines, I am very excited about understanding how the brain works. Check out publications to follow recent progress.\nI did my PhD at Stanford University with Dr. Bernard Widrow, one of the pioneers of neural networks. During my PhD time I co-founded Numenta with Jeff Hawkins and Donna Dubinsky. Numenta was founded in 2005, and I was the CTO when I left in 2010 to start Vicarious. In my PhD thesis I developed a hierarhical and temporal model (HTM) for vision, which formed the core Hierarchical Temporal Memory work done at Numenta up to 2010.\n","date":1619049600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1619049600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am an engineer, scientist, and entrepreneur working at the intersection of artficial intelligence, neuroscience, and robotics. My long-term goal is to build human-level intelligence based on the principles we learn from cognitive science and neuroscience. To this end, I co-founded Vicarious AI with Scott Phoenix. Check out our projects at www.vicarious.com\nIn addition to building intelligent machines, I am very excited about understanding how the brain works. Check out publications to follow recent progress.","tags":null,"title":"Dileep George","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I'll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I'll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"87f003334bbe8fd592b20d51af9fa06c","permalink":"/talks/lex/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/lex/","section":"talks","summary":"  ","tags":null,"title":"Biologically inspired machine intelligence. Podcast with Lex Fridman","type":"talks"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":null,"categories":null,"content":"  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"327a64ef01e418586412048716694cb8","permalink":"/talks/cto/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/cto/","section":"talks","summary":"  ","tags":null,"title":"Modern CTO: Interview with Joel Beasley","type":"talks"},{"authors":null,"categories":null,"content":"  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"fc802e89e5331479b4774a3e7d669427","permalink":"/talks/space_seq/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/space_seq/","section":"talks","summary":"  ","tags":null,"title":"Space is a sequence: Unifying space and time in the hippocampus","type":"talks"},{"authors":null,"categories":null,"content":"  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"fde52857f88f117e48e908e8c0ee1015","permalink":"/talks/commsense/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/commsense/","section":"talks","summary":"  ","tags":null,"title":"TwiML Conversation with Sam Charrington: Commonsense as an algorithmic framework","type":"talks"},{"authors":null,"categories":null,"content":"  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0707c123acd176d9bc8ec914af07c63d","permalink":"/talks/brain3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/brain3/","section":"talks","summary":"  ","tags":null,"title":"Brain Inspired. Podcast with Paul Middlebrooks. Episode 87. Cloning for Cognitive Maps","type":"talks"},{"authors":null,"categories":null,"content":"  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c0553641d18b0ace05db379709089183","permalink":"/talks/agi_conference/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/agi_conference/","section":"talks","summary":"  ","tags":null,"title":"Keynote at HLAI conference: Building Machines that work like the brain.","type":"talks"},{"authors":null,"categories":null,"content":"  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"2318000d035c6e1569be76a94c2e2766","permalink":"/talks/brain1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/brain1/","section":"talks","summary":"  ","tags":null,"title":"Brain Inspired. Podcast with Paul Middlebrooks. Episode 13","type":"talks"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic's Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Dileep George","Rajeev V. Rikye,","Nishad Gothoskar,","J. Swaroop Guntupalli,","Antoine Dedieu,","Miguel L√°zaro-Gredilla"],"categories":null,"content":" Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1619049600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619049600,"objectID":"0feeb499e0beae5b3f068735c7657c8c","permalink":"/publication/cogmaps-natcomm/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cogmaps-natcomm/","section":"publication","summary":"Cognitive maps are mental representations of spatial and conceptual relationships in an environment, and are critical for flexible behavior. To form these abstract maps, the hippocampus has to learn to separate or merge aliased observations appropriately in different contexts in a manner that enables generalization and efficient planning. Here we propose a specific higher-order graph structure, clone-structured cognitive graph (CSCG), which forms clones of an observation for different contexts as a representation that addresses these problems. CSCGs can be learned efficiently using a probabilistic sequence model that is inherently robust to uncertainty. We show that CSCGs can explain a variety of cognitive map phenomena such as discovering spatial relations from aliased sensations, transitive inference between disjoint episodes, and formation of transferable schemas. Learning different clones for different contexts explains the emergence of splitter cells observed in maze navigation and event-specific responses in lap-running experiments. Moreover, learning and inference dynamics of CSCGs offer a coherent explanation for disparate place cell remapping phenomena. By lifting aliased observations into a hidden space, CSCGs reveal latent modularity useful for hierarchical abstraction and planning. Altogether, CSCG provides a simple unifying framework for understanding hippocampal function, and could be a pathway for forming relational abstractions in artificial intelligence.","tags":["Source Themes"],"title":"Clone-structured graph representations enable flexible learning and vicarious evaluation of cognitive maps","type":"publication"},{"authors":["Dileep George","Miguel Lazaro-Gredilla","Wolfgang Lehrach","Antoine Dedieu","Guangyao Zhou"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1601510400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601510400,"objectID":"68e544788f1aeb2a4413b92941c8d462","permalink":"/publication/cortical-microcircuits/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cortical-microcircuits/","section":"publication","summary":"Understanding the information processing roles of cortical circuits is an outstanding problem in neuroscience and artificial intelligence. Theory-driven efforts will be required to tease apart the functional logic of cortical circuits from the vast amounts of experimental data on cortical connectivity and physiology. Although the theoretical setting of Bayesian inference has been suggested as a framework for understanding cortical computation, making precise and falsifiable biological mappings need models that tackle the challenge of real world tasks. Based on a recent generative model, Recursive Cortical Networks, that demonstrated excellent performance on visual task benchmarks, we derive a family of anatomically instantiated and functional cortical circuit models. Efficient inference and generalization guided the representational choices in the original computational model. The cortical circuit model is derived by systematically comparing the computational requirements of this model with known anatomical constraints. The derived model suggests precise functional roles for the feed-forward, feedback, and lateral connections observed in different laminae and columns, assigns a computational role for the path through the thalamus, predicts the interactions between blobs and inter-blobs, and offers an algorithmic explanation for the innate inter-laminar connectivity between clonal neurons within a cortical column. The model also explains several visual phenomena, including the subjective contour effect, and neon-color spreading effect, with circuit-level precision. Our work paves a new path forward in understanding the logic of cortical and thalamic circuits.","tags":["Source Themes"],"title":"A detailed mathematical theory of thalamic and cortical microcircuits based on inference in a generative vision model","type":"publication"},{"authors":[],"categories":[],"content":"","date":1583712419,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583712419,"objectID":"b74e568940289f96574de965983cf96e","permalink":"/pubcopy/sample_pub_2/","publishdate":"2020-03-08T17:06:59-07:00","relpermalink":"/pubcopy/sample_pub_2/","section":"pubcopy","summary":"","tags":[],"title":"Sample_pub_2","type":"pubcopy"},{"authors":["Daniel P. Sawyer","Miguel L√°zaro-Gredilla","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580515200,"objectID":"21c1beaea88e6521701c75b609f6b37d","permalink":"/publication/fast-cognitive-programs/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/fast-cognitive-programs/","section":"publication","summary":"The ability of humans to quickly identify general concepts from a handful of images has proven difficult to emulate with robots. Recently, a computer architecture was developed that allows robots to mimic some aspects of this human ability by modeling concepts as cognitive programs using an instruction set of primitive cognitive functions. This allowed a robot to emulate human imagination by simulating candidate programs in a world model before generalizing to the physical world. However, this model used a naive search algorithm that required 30 minutes to discover a single concept, and became intractable for programs with more than 20 instructions. To circumvent this bottleneck, we present an algorithm that emulates the human cognitive heuristics of object factorization and sub-goaling, allowing human-level inference speed, improving accuracy, and making the output more explainable.","tags":["Source Themes"],"title":"A Model of Fast Concept Inference with Object-Factorized Cognitive Programs","type":"publication"},{"authors":["Rajeev V. Rikye,","Nishad Gothoskar,","J. Swaroop Guntupalli,","Antoine Dedieu,","Miguel L√°zaro-Gredilla","Dileep George"],"categories":null,"content":" Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"476f20f1d5c5831653bb7770d137d033","permalink":"/publication/cognitive-maps-biorxiv/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cognitive-maps-biorxiv/","section":"publication","summary":"Cognitive maps enable us to learn the layout of environments, encode and retrieve episodic memories, and navigate vicariously for mental evaluation of options. A unifying model of cognitive maps will need to explain how the maps can be learned scalably with sensory observations that are non-unique over multiple spatial locations (aliased), retrieved efficiently in the face of uncertainty, and form the fabric of efficient hierarchical planning. We propose learning higher-order graphs ‚Äì structured in a specific way that allows efficient learning, hierarchy formation, and inference ‚Äì as the general principle that connects these different desiderata. We show that these graphs can be learned efficiently from experienced sequences using a cloned Hidden Markov Model (CHMM), and uncertainty-aware planning can be achieved using message-passing inference. Using diverse experimental settings, we show that CHMMs can be used to explain the emergence of context-specific representations, formation of transferable structural knowledge, transitive inference, shortcut finding in novel spaces, remapping of place cells, and hierarchical planning. Structured higher-order graph learning and probabilistic inference might provide a simple unifying framework for understanding hippocampal function, and a pathway for relational abstractions in artificial intelligence.","tags":["Source Themes"],"title":"Learning cognitive maps as structured graphs for vicarious evaluation","type":"publication"},{"authors":["Miguel Lazaro-Gredilla","Wolfgang Lehrach","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1575158400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575158400,"objectID":"741be7195a629e675493c90d866fff62","permalink":"/publication/bayesian-qt/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/bayesian-qt/","section":"publication","summary":"Query training is a a technique that lets you train graphical models using ideas from deep learning.","tags":["Source Themes"],"title":"Learning undirected models via query training","type":"publication"},{"authors":["Nishad Gothoskar","J. Swaroop Guntupalli","Rajeev Rikhye","Miguel Lazaro-Gredilla","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"3840cdbddef40e8a391ef87422d8951e","permalink":"/publication/ccn-different-clones/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/ccn-different-clones/","section":"publication","summary":"Hippocampus encodes cognitive maps that support episodic memories, navigation, and planning. Under-standing the commonality among those maps as well as how those maps are structured, learned from experience, and used for inference and planning is an interesting but unsolved problem. We propose higher-order graphs as the general principle and present, as a plausible model, a cloned hidden Markov model (HMM) that can learn these graphs efficiently from experienced sequences. In our experiments, we use the cloned HMM for learning spatial and abstract representations. We show that inference and planning in the learned CHMM encapsulates many of the key properties of hippocampal cells observed in rodents and humans. Cloned HMM thus provides a new frame-work for understanding hippocampal function.","tags":["Source Themes"],"title":"Different clones for different contexts: Hippocampal cognitive maps as higher-order graphs of a cloned HMM","type":"publication"},{"authors":["Rajeev Rikhye","Nishad Gothoskar","J. Swaroop Guntupalli","Miguel Lazaro-Gredilla","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"2f9133999c0732e6dc9bb62024d0ea96","permalink":"/publication/ccn-memorize-generalize/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/ccn-memorize-generalize/","section":"publication","summary":"Sequence learning is a vital cognitive function and has been observed in numerous brain areas. Discovering the algorithms underlying sequence learning has been a major endeavour in both neuroscience and machine learning. In earlier work we showed that by constraining the sparsity of the emission matrix of a Hidden Markov Model (HMM) in a biologically-plausible manner we are able to efficiently learn higher-order temporal dependencies and recognize contexts in noisy signals. The central basis of our model, referred to as the Cloned HMM (CHMM), is the observation that cortical neurons sharing the same receptive field properties can learn to represent unique incidences of bottom-up information within different temporal contexts. CHMMs can efficiently learn higher-order temporal dependencies, recognize long-range contexts and, unlike recurrent neural networks, are able to natively handle uncertainty. In this paper we introduce a biologically plausible CHMM learning algorithm, memorize-generalize, that can rapidly memorize sequences as they are encountered, and gradually generalize as more data is accumulated. We demonstrate that CHMMs trained with the memorize-generalize algorithm can model long-range structure in bird songs with only a slight degradation in performance compared to expectation-maximization, while still outperforming other representations.","tags":["Source Themes"],"title":"Memorize-Generalize: An online algorithm for learning higher-order sequential structure with cloned Hidden Markov Models","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you'll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Did you find this page helpful? Consider sharing it üôå ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you'll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Antoine Dedieu‚àó‚Ä†","Nishad Gothoskar‚àó‚Ä†","Scott Swingle","Wolfgang Lehrach","Miguel Lazaro-Gredilla","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1556668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556668800,"objectID":"4378d753d3a20cc56d13b5f51940edbe","permalink":"/publication/cloned-hmm/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cloned-hmm/","section":"publication","summary":"Variable order sequence modeling is an important problem in artificial and natural intelligence. While overcomplete Hidden Markov Models (HMMs), in theory, have the capacity to represent long-term tem- poral structure, they often fail to learn and converge to local minima. We show that by constraining HMMs with a simple sparsity structure inspired by biology, we can make it learn variable order sequences efficiently. We call this model cloned HMM (CHMM) because the sparsity structure enforces that many hidden states map deterministically to the same emission state. CHMMs with over 1 billion parameters can be efficiently trained on GPUs without being severely affected by the credit diffusion problem of standard HMMs. Unlike n-grams and sequence memoizers, CHMMs can model temporal dependencies at arbitrarily long distances and recognize contexts with ‚Äúholes‚Äù in them. Compared to Recurrent Neural Networks and their Long Short-Term Memory extensions (LSTMs), CHMMs are generative models that can natively deal with uncertainty. Moreover, CHMMs return a higher-order graph that represents the temporal structure of the data which can be useful for community detection, and for building hierarchical models. Our experiments show that CHMMs can beat n-grams, sequence memoizers, and LSTMs on character-level language modeling tasks. CHMMs can be a viable alternative to these methods in some tasks that require variable order sequence modeling and the handling of uncertainty.","tags":["Source Themes"],"title":"Learning higher-order sequential structure with cloned HMMs","type":"publication"},{"authors":["Dileep George"],"categories":null,"content":" Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"0a2ea1511655e0b7124dd28830e1da8b","permalink":"/pubcopy/cognitive-maps-biorxiv/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/pubcopy/cognitive-maps-biorxiv/","section":"pubcopy","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"Learning cognitive maps for vicarious evaluation","type":"pubcopy"},{"authors":["Dileep George"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post's folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\n Trial \u0026ndash;\nFeatures  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let's make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let's make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"4553ea2b6020e42c94eb11635f5338ad","permalink":"/slides_copy/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides_copy/example/","section":"slides_copy","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides_copy"},{"authors":["Miguel Lazaro-Gredilla","Dianhuan Lian","J. Swaroop Guntupalli","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"618a01ff7d8156738f668c3f6ed2110a","permalink":"/publication/cognitive-programs/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cognitive-programs/","section":"publication","summary":"Concepts are formalized as programs on a special computer architectrue called the Visual Cognitive Computer (VCC). By learning programs on VCC, concepts transfer from schematic inputs to real-wrold robots.","tags":["Source Themes"],"title":"Beyond Imitation: Zero-shot task transfer on robots by learning concepts as cognitive programs","type":"publication"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"d9e68254619f7503a07c84b6b4bcc5d8","permalink":"/comics_landing_page/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/comics_landing_page/","section":"","summary":"Hello!","tags":null,"title":"Landing Page","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"174ade0c418f99f8353d1026864d9de8","permalink":"/research_landing_page/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/research_landing_page/","section":"","summary":"Hello!","tags":null,"title":"Landing Page","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"030228919036e6d5ad1ff8c79cff987d","permalink":"/talks_landing_page/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/talks_landing_page/","section":"","summary":"Hello!","tags":null,"title":"Landing Page","type":"widget_page"},{"authors":["Dileep George","Wolfgang Lehrach","Miguel Lazaro-Gredilla"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"a3475d19da2cb744b1428ed23055110c","permalink":"/publication/cortical-circuits-ccn/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cortical-circuits-ccn/","section":"publication","summary":"A hierarchical vision model that emphasizes the role of lateral and feedback connections and treats classification, segmentation geneeration, and occlusion-reasoning in a unified framework.","tags":["Source Themes"],"title":"Cortical micro-circuits from a generative vision model","type":"publication"},{"authors":["Dileep George","Wolfgang Lehrach","Miguel Lazaro-Gredilla"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1538352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538352000,"objectID":"2b0cab30b25fa516f5e4b3154f8a16df","permalink":"/publication/cortical-phenom-ccn/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cortical-phenom-ccn/","section":"publication","summary":"A hierarchical vision model that emphasizes the role of lateral and feedback connections and treats classification, segmentation geneeration, and occlusion-reasoning in a unified framework.","tags":["Source Themes"],"title":"Explaining Visual Cortex Phenomena using Recursive Cortical Network","type":"publication"},{"authors":null,"categories":null,"content":"Featured tweet threads     Thread about our paper on learning generative cognitive maps as higher-order graphs Are you skeptical about successor representations? Want to know how our new model can learn cognitive maps, context-specific representations, do transitive inference, and flexible hierarchical planning? #tweeprint...(1) @vicariousai @swaroopgj @rvrikhye https://t.co/4WOiJMPBvU https://t.co/TuUFHr27Iq\n\u0026mdash; Dileep George (@dileeplearning) December 7, 2019      Predicted the flow of AI debate between Yoshua Bengio and Gary Marcus\u0026hellip; Can\u0026#39;t wait for the upcoming \u0026#39;future of AI\u0026#39; debate between @GaryMarcus and Yoshua Bengio at @Montreal_AI? Then read #AGIcomics pre-coverage of the epic event with predictions of punches and counter-punches üôÉ...Thread (1/9) https://t.co/SED5AL1FUJ pic.twitter.com/S5JOMi3dM0\n\u0026mdash; Dileep George (@dileeplearning) November 27, 2019       Artificial general accomplishments in AI\u0026hellip;.. #AGI series returns after a summer break! This one tackles the tricky question of accomplishments! ... some older comics in the thread. #AGIcomics pic.twitter.com/H5m1VP7khk\n\u0026mdash; Dileep George (@dileeplearning) August 31, 2019      Most deep learning generative models use amortized inference. i.e, their encoders are trained to answer only a particular kind of query. How do we train graphical models to answer arbitrary queries? We want generative models to be flexible, but models like VAEs answer only the trained query. To have inference networks that answer arbitrary queries, we introduce query-training. See it at the approx Bayes sympsm if you are at #NeurIPS2019 ...(1) https://t.co/F2z1C20PEy\n\u0026mdash; Dileep George (@dileeplearning) December 8, 2019     ","date":1530144000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530144000,"objectID":"0eb8e1784aa9b0af049b002099490448","permalink":"/tweets/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/tweets/","section":"","summary":"Sometime tweets are not ephemeral.","tags":null,"title":"","type":"page"},{"authors":null,"categories":null,"content":"I am motivated by the quest to undertsand how the brain works and to build machines that work like the brain. I consider these two problems as intimately interlinked. Understanding the principles of operation of the brain will help us make machines that think and generalize like us, and building such machines is a necessary component to understanding how the cortical circuitry works. I am fortunate in being able to collaborate with a set of excellent researchers at Vicarious to grapple with these problems.\nWe are one of the few groups that pore over neuroanatomical, nueurophysiological, and behavioral data with the aim of learning useful computational principles from the brain. Some of the results from these investigations are in the papers and manuscripts below.\nCompositional generative models for perception A generative vision model that trains with high data-efficiency breaks text based captchas. Science 2017\nThis model emphasized\n Top-down attention Lateral \u0026amp; Feedback connections Factorized representation of shape and appearance (contours and surfaces) Border-ownership Iterative inference that has feed-forward, feedback, lateral, and explaining away interactions.  From CAPTCHA to common sense: How brain can teach us about artificial intelligence. Frontiers 2020\n Gives more details of the connection of the above model to principles learned from neuro/cognitive science Discussions on AGI, evolution, inductive biases etc.  Attention-controllable border-ownership for objectness and binding \nObject-based Generative models for dynamics Schema networks: Zero-shot transfer with a generative causal model of intuitive physics. ICML 2017\n Schema representations that abstracient and generalize. Partially based on ideas from Drescher's excellent book. Also related to schemas in the prefrontal cortex.  Cognitive programs \u0026amp; Visual cognitive computer \u0026ndash; a cognitive architecture to learn abstract concepts Zero-shot task transfer on robots by learning concepts as cognitive programs. Science Robotics 2019\n Brain as a biased computer with generative perception and dynamics, controllable top-down attention, and working memory Concepts and abstractions are programs on this visual cognitive computer.  A Model of Fast Concept Inference with Object-Factorized Cognitive Programs. CogSci 2020\n Object-factorized, sub-goaling based cognitive programs.  Episodic memory and cognitive maps Clone-structured graph representations enable flexible learning and vicarious evaluatiton of cognitive maps. Nature Communications 2021\n Hippocampus as structured higher-order sequence learning. \u0026ldquo;Spatial\u0026rdquo; represenations emerge from ordinal sequence learning. Explanations for wide array of hippocampal effects.  Memorize-Generalize: An online algorithm for learning cognitive maps. CCN 2019\n Shows how to learn cognitive maps using fast episodic memory followed by slower consolidation  Hand-eye coordination and visual servoing Neuroscience Understanding cortical and thalamic circuits\n Cognitive Maps and hippocampus  ","date":1530144000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530144000,"objectID":"9112f8e7efb2556d4a242db7f00d8d6d","permalink":"/research_old/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/research_old/","section":"","summary":"I am motivated by the quest to undertsand how the brain works and to build machines that work like the brain. I consider these two problems as intimately interlinked. Understanding the principles of operation of the brain will help us make machines that think and generalize like us, and building such machines is a necessary component to understanding how the cortical circuitry works. I am fortunate in being able to collaborate with a set of excellent researchers at Vicarious to grapple with these problems.","tags":null,"title":"Research","type":"page"},{"authors":["Nicholas Hay","Michael Stark","Alexander Schlegel","Carter Wendelken","Dennis Park","Eric Purdy","Tom Silver","D. Scott Phoenix","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1517443200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517443200,"objectID":"9fcb78451ab8ddca3e3dee641f0622e2","permalink":"/publication/smc-aaai/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/smc-aaai/","section":"publication","summary":"AI has seen remarkable progress in recent years, due to a switch from hand-designed shallow representations, to learned deep representations. While these methods excel with plentiful training data, they are still far from the human ability to learn concepts from just a few examples by reusing previously learned conceptual knowledge in new contexts. We argue that this gap might come from a fundamental misalignment between human and typical AI representations: while the former are grounded in rich sensorimotor expe- rience, the latter are typically passive and limited to a few modalities such as vision and text. We take a step towards closing this gap by proposing an interactive, behavior-based model that represents concepts using sensorimotor contingencies grounded in an agent‚Äôs experience. On a novel conceptual learning and benchmark suite, we demonstrate that conceptually meaningful behaviors can be learned, given supervision via training curricula.","tags":["Source Themes"],"title":"Behavior is Everything: Towards Representing Concepts with Sensorimotor Contingencies","type":"publication"},{"authors":["Dileep George","Wolfgang Lehrach","Ken Kansky","Miguel Lazaro-Gredilla","Christopher Laan","Bhaskara Marthi","Xinghua Lou","Zhaoshi Meng","Yi Liu","Huayan Wang","Alex Lavin","D. Scott Phoenix"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1506816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506816000,"objectID":"fd6d8e497976c2414b6d3e307e0f1fba","permalink":"/publication/science-captcha/","publishdate":"2017-08-08T00:00:00Z","relpermalink":"/publication/science-captcha/","section":"publication","summary":"Learning from a few examples and generalizing to markedly different situations are capabilities of human visual intelligence that are yet to be matched by leading machine learning models. By drawing inspiration from systems neuroscience, we introduce a probabilistic generative model for vision in which message-passing‚Äìbased inference handles recognition, segmentation, and reasoning in a unified way. The model demonstrates excellent generalization and occlusion-reasoning capabilities and outperforms deep neural networks on a challenging scene text recognition benchmark while being 300-fold more data efficient. In addition, the model fundamentally breaks the defense of modern text-based CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) by generatively segmenting characters without CAPTCHA-specific heuristics. Our model emphasizes aspects such as data efficiency and compositionality that may be important in the path toward general artificial intelligence.","tags":["Source Themes"],"title":"A generative model for vision that trains with high data efficiency and breaks text-based CAPTCHAs","type":"publication"},{"authors":["Ken Kansky","Tom Silver","David A. M√©ly","Mohamed Eldawy,","Miguel L√°zaro-Gredilla,","Xinghua Lou,","Nimrod Dorfman,","Szymon Sidor","Scott Phoenix","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1504224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1504224000,"objectID":"f32ba337724c95e48efc302314b06b65","permalink":"/publication/schema-networks/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/schema-networks/","section":"publication","summary":"The recent adaptation of deep neural network-based methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks. Nonetheless, progress on task-to-task transfer remains limited. In pursuit of efficient and robust generalization, we introduce the Schema Network, an object-oriented generative physics simulator capable of disentangling multiple causes of events and reasoning backward through causes to achieve goals. The richly structured architecture of the Schema Network can learn the dynamics of an environment directly from data. We compare Schema Networks with Asynchronous Advantage Actor-Critic and Progressive Networks on a suite of Breakout variations, reporting results on training efficiency and zero-shot generalization, consistently demonstrating faster, more robust learning and better transfer. We argue that generalizing from limited data and learning causal relationships are essential abilities on the path toward generally intelligent systems.","tags":["Source Themes"],"title":"Schema Networks: Zero-shot transfer with a generative causal model of  intuitive physics","type":"publication"},{"authors":["Miguel L√°zaro-Gredilla","Yi Liu,","D. Scott Phoenix,","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496275200,"objectID":"0abd085eb8a2dd40fe539dc9c4427de8","permalink":"/publication/hcn-feature-learning/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/hcn-feature-learning/","section":"publication","summary":"We introduce the hierarchical compositional network (HCN), a directed generative model able to discover and disentangle, without supervision, the building blocks of a set of binary images. The building blocks are binary features defined hierarchically as a composition of some of the features in the layer immediately below, arranged in a particular manner. At a high level, HCN is similar to a sigmoid belief network with pooling. Inference and learning in HCN are very challenging and existing variational approximations do not work satisfactorily. A main contribution of this work is to show that both can be addressed using max-product message passing (MPMP) with a particular schedule (no EM required). Also, using MPMP as an inference engine for HCN makes new tasks simple: adding supervision information, classifying images, or performing inpainting all correspond to clamping some variables of the model to their known values and running MPMP on the rest. When used for classification, fast inference with HCN has exactly the same functional form as a convolutional neural network (CNN) with linear activations and binary weights. However, HCN's features are qualitatively very different.","tags":["Source Themes"],"title":"Hierarchical Compositional Feature Learning","type":"publication"},{"authors":["Austin Stone","Huayan Wang","Michael Stark","Yi Liu","D. Scott Phoenix","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1496275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1496275200,"objectID":"dda2e321b374d2c664a59f904d57e68c","permalink":"/publication/teaching-compositionality/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/teaching-compositionality/","section":"publication","summary":"Convolutional neural networks (CNNs) have shown great success in computer vision, approaching human-level performance when trained for specific tasks via application-specific loss functions. In this paper, we propose a method for augmenting and training CNNs so that their learned features are compositional. It encourages networks to form representations that disentangle objects from their surroundings and from each other, thereby promoting better generalization. Our method is agnostic to the specific details of the underlying CNN to which it is applied and can in principle be used with any CNN. As we show in our experiments, the learned representations lead to feature activations that are more localized and improve performance over non-compositional baselines in object recognition tasks.","tags":["Source Themes"],"title":"Teaching compositionality to CNNs","type":"publication"},{"authors":["Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"b4f085f28ef15c8a887d16ae4281a4c1","permalink":"/publication/bbs-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/bbs-article/","section":"publication","summary":"This paper is an invited commentary on Lake et al's Behavioral and Brain Sciences article titled \"Building machines that learn and think like people\". Lake et al's paper offers a timely critique on the recent accomplishments in artificial intelligence from the vantage point of human intelligence, and provides insightful suggestions about research directions for building more human-like intelligence. Since we agree with most of the points raised in that paper, we will offer a few points that are complementary","tags":["Source Themes"],"title":"What can the brain teach us about building artificial intelligence?","type":"publication"},{"authors":["Xinghua Lou","Ken Kansky","Wolfgang Lehrach","CC Laan","Bhaskara Marthi","D. Scott Phoenix","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1480550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480550400,"objectID":"b2a04b58670d35db7c04ab92881a86cd","permalink":"/publication/generative-shape/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/generative-shape/","section":"publication","summary":"Learning from a few examples and generalizing to markedly different situations are capabilities of human visual intelligence that are yet to be matched by leading machine learning models. By drawing inspiration from systems neuroscience, we introduce a probabilistic generative model for vision in which message-passing‚Äìbased inference handles recognition, segmentation, and reasoning in a unified way. The model demonstrates excellent generalization and occlusion-reasoning capabilities and outperforms deep neural networks on a challenging scene text recognition benchmark while being 300-fold more data efficient. In addition, the model fundamentally breaks the defense of modern text-based CAPTCHAs (Completely Automated Public Turing test to tell Computers and Humans Apart) by generatively segmenting characters without CAPTCHA-specific heuristics. Our model emphasizes aspects such as data efficiency and compositionality that may be important in the path toward general artificial intelligence.","tags":["Source Themes"],"title":"Generative shape models","type":"publication"},{"authors":null,"categories":null,"content":"What if AGI is already here, just misaligned?\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"3e289fcb94d4d63913115fd7ba33b000","permalink":"/agi_comics/ag_alignment/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_alignment/","section":"agi_comics","summary":"What if AGI is already here, just misaligned?","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"Why is the trolley problem not relevant for trolleys?\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"cbc3c25a5de3f5f0f385ec3d1e9aa8a3","permalink":"/agi_comics/ag_dilemma/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_dilemma/","section":"agi_comics","summary":"Why is the trolley problem not relevant for trolleys?","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"Why deep learning is really like the brain..\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"2733ec82a056402a38cc97fb88ac6942","permalink":"/agi_comics/ag_equivalence/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_equivalence/","section":"agi_comics","summary":"Why deep learning is really like the brain..","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"A flow chart to predict the future of AI!\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"a9dfd6136d7ccf5b922446e345c61cf8","permalink":"/agi_comics/ag_future/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_future/","section":"agi_comics","summary":"Move over TensorFlow...","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"Domain knowledge is included\u0026hellip;\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"afb3bd6f70feb09ff4777568b4c3b16a","permalink":"/agi_comics/ag_generality/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_generality/","section":"agi_comics","summary":"Domain knowledge is included...","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"One can always appreciate some humility, especially this kind\u0026hellip;\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"3b17e96ddbf99f3b8412e418dae599fa","permalink":"/agi_comics/ag_humility/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_humility/","section":"agi_comics","summary":"One can always appreciate some humility, especially this kind...","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"what if planes were built without inspiration from birds?\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d548695905041b49d9c33fbcf3280d9b","permalink":"/agi_comics/ag_inspiration/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_inspiration/","section":"agi_comics","summary":"what if planes were built without inspiration from birds?","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"how do you know AGI is not already here?\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"32d9891d71df0905103da81267db4175","permalink":"/agi_comics/ag_irrelevance/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_irrelevance/","section":"agi_comics","summary":"how do you know AGI is not already here?","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"Sometimes you need a lengthy preface\u0026hellip;.or more friends\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"985ca230460e77b7bb5dad589408b0cc","permalink":"/agi_comics/ag_preface/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_preface/","section":"agi_comics","summary":"Sometimes you need a lengthy preface..","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"Too bad reality isn't like an Atari game..\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"1fe7ef4da04cb860781f47c2574de02d","permalink":"/agi_comics/ag_reality/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_reality/","section":"agi_comics","summary":"Too bad reality isn't like an Atari game..","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"Happy 2020 hindsight about AGI!\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d164a60c989accd8d02fe6c6abc4128e","permalink":"/agi_comics/ag_viewpoints/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_viewpoints/","section":"agi_comics","summary":"Happy 2020 hindsight about AGI!","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"Wish you 2020 AGI hindsight\u0026hellip;\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"3b62f95c5a557aac1760fbf8b846db9f","permalink":"/agi_comics/ag_wish/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_wish/","section":"agi_comics","summary":"Wish you 2020 AGI hindsight...","tags":["Demo"],"title":"","type":"agi_comics"},{"authors":null,"categories":null,"content":"Some definitions are very convenient\u0026hellip;\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e964a760b695d6177c45fb608431c308","permalink":"/agi_comics/ag_definition/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_definition/","section":"agi_comics","summary":"Some definitions are very convenient..","tags":["AGIComics"],"title":"Artifical General Definition","type":"agi_comics"},{"authors":null,"categories":null,"content":"Things that are easy for humans are often the hardest for AI!\n  ","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"7a7a01c3bacd9eee09a797afed67db36","permalink":"/agi_comics/ag_accomplishment/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_accomplishment/","section":"agi_comics","summary":"Things that are easy for humans are often the hardest for AI!\n  ","tags":null,"title":"Artificial General Accomplishment","type":"agi_comics"},{"authors":null,"categories":null,"content":"Some debates can be generally artificial\u0026hellip;.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"2aef57762eac01d0b200020a9aa843ed","permalink":"/agi_comics/ag_debate/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/agi_comics/ag_debate/","section":"agi_comics","summary":"Some debates can be generally artificial...","tags":["Demo"],"title":"Artificial General Debate","type":"agi_comics"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"1c324ef234bc87c93046772bdf074da9","permalink":"/project/generative-vision/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/generative-vision/","section":"project","summary":"How does the brain learn a generative model for vision? How is that model used for inference? How can this generative model help to learn abstractions?","tags":["Generative Models","Bayesian Inference \u0026 Predictive Coding","Visual inference"],"title":"Compositional Generative Vision","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"16ac0d24e33b19d81dc2252d51ec6bfd","permalink":"/project/generative-dynamics/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/generative-dynamics/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"project"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"f6db4f209ecd9c9fa49ab5116eb918b7","permalink":"/project/cognitive-programs/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/cognitive-programs/","section":"project","summary":"What is the cognitive architecture that enabels concept learning? How do humans learn concepts? How can we have machines that learn abstract concepts as effectively as humans?","tags":null,"title":"Learning abstract concepts as cognitive programs","type":"project"},{"authors":["Dileep George"],"categories":["Demo"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\nCheck out the latest demo of what you'll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n üëâ Get Started üìö View the documentation üí¨ Ask a question on the forum üë• Chat with the community üê¶ Twitter: @source_themes @GeorgeCushen #MadeWithAcademic üí° Request a feature or report a bug ‚¨ÜÔ∏è Updating? View the Update Guide and Release Notes ‚ù§ Support development of Academic:  ‚òïÔ∏è Donate a coffee üíµ Become a backer on Patreon üñºÔ∏è Decorate your laptop or journal with an Academic sticker üëï Wear the T-shirt üë©‚Äçüíª Contribute       Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["Dileep George","Wolfgang Lehrach","Miguel Lazaro-Gredilla"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"c0687c8edc763ebdc6116e6983785852","permalink":"/pubcopy/science-captcha/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/pubcopy/science-captcha/","section":"pubcopy","summary":"A hierarchical vision model that emphasizes the role of lateral and feedback connections and treats classification, segmentation geneeration, and occlusion-reasoning in a unified framework.","tags":["Source Themes"],"title":"A generative model for vision","type":"pubcopy"},{"authors":["Dileep George","Miguel Lazaro-Gredilla","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"7aa6c392e4a83de96be0c759e929b622","permalink":"/pubcopy/cognitive-programs/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/pubcopy/cognitive-programs/","section":"pubcopy","summary":"Concepts are formalized as programs on a special computer architectrue called the Visual Cognitive Computer (VCC). By learning programs on VCC, concepts transfer from schematic inputs to real-wrold robots.","tags":["Source Themes"],"title":"Learning concepts as cognitive programs","type":"pubcopy"},{"authors":["Dileep George","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"e983f7c1bcb53103d8576f5e7aa5592d","permalink":"/pubcopy/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/pubcopy/conference-paper/","section":"pubcopy","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"pubcopy"},{"authors":["Dileep George","Jeff Hawkins"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1251763200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1251763200,"objectID":"d5452ae0ada3f9c03b53e37bfd6801a2","permalink":"/publication/plos-cortical-circuits/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/plos-cortical-circuits/","section":"publication","summary":"The theoretical setting of hierarchical Bayesian inference is gaining acceptance as a framework for understanding cortical computation. In this paper, we describe how Bayesian belief propagation in a spatio-temporal hierarchical model, called Hierarchical Temporal Memory (HTM), can lead to a mathematical model for cortical circuits. An HTM node is abstracted using a coincidence detector and a mixture of Markov chains. Bayesian belief propagation equations for such an HTM node define a set of functional constraints for a neuronal implementation. Anatomical data provide a contrasting set of organizational constraints. The combination of these two constraints suggests a theoretically derived interpretation for many anatomical and physiological features and predicts several others. We describe the pattern recognition capabilities of HTM networks and demonstrate the application of the derived circuits for modeling the subjective contour effect. We also discuss how the theory and the circuit can be extended to explain cortical features that are not explained by the current model and describe testable predictions that can be derived from the model.","tags":["Source Themes"],"title":"Towards a Mathematical Theory of Cortical Micro-circuits","type":"publication"},{"authors":["Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1220227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1220227200,"objectID":"3bbaff791be1d67f99d1269bde41adc9","permalink":"/publication/phd-thesis/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/phd-thesis/","section":"publication","summary":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","tags":["Source Themes"],"title":"How the brain might work: A hierarchical model of learning and recognition","type":"publication"},{"authors":["Jeff Hawkins","Dileep George","Jamie Niemasik"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1220227200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1220227200,"objectID":"7545ada921a066068d3f03fdafd1ccd0","permalink":"/publication/royal_society_seq/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/royal_society_seq/","section":"publication","summary":"In this paper, we propose a mechanism which the neocortex may use to store sequences of patterns. Storing and recalling sequences are necessary for making predictions, recognizing time-based patterns and generating behaviour. Since these tasks are major functions of the neocortex, the ability to store and recall time-based sequences is probably a key attribute of many, if not all, cortical areas. Previously, we have proposed that the neocortex can be modelled as a hierarchy of memory regions, each of which learns and recalls sequences. This paper proposes how each region of neocortex might learn the sequences necessary for this theory. The basis of the proposal is that all the cells in a cortical column share bottom-up receptive field properties, but individual cells in a column learn to represent unique incidences of the bottom-up receptive field property within different sequences. We discuss the proposal, the biological constraints that led to it and some results modelling it.","tags":["Source Themes"],"title":"Sequence memory for prediction, inference and behaviour","type":"publication"},{"authors":["Dileep George","Jeff Hawkins"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1125532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1125532800,"objectID":"4850103e5cdf3d9b6bd7b49cf1d08ad7","permalink":"/publication/ijcnn-bayesian/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/ijcnn-bayesian/","section":"publication","summary":" We describe a hierarchical model of invariant visual pattern recognition in the visual cortex. In this model, the knowledge of how patterns change when objects move is learned and encapsulated in terms of high probability sequences at each level of the hierarchy. Configuration of object parts is captured by the patterns of coincident high probability sequences. This knowledge is then encoded in a highly efficient Bayesian Network structure.The learning algorithm uses a temporal stability criterion to discover object concepts and movement patterns. We show that the architecture and algorithms are biologically plausible. The large scale architecture of the system matches the large scale organization of the cortex and the micro-circuits derived from the local computations match the anatomical data on cortical circuits. The system exhibits invariance across a wide variety of transformations and is robust in the presence of noise. Moreover, the model also offers alternative explanations for various known cortical phenomena.","tags":["Source Themes"],"title":"A Hierarchical Bayesian Model of Invariant Pattern Recognition in the Visual Cortex","type":"publication"},{"authors":["Pat Langley","Dileep George"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Click the Slides button above to demo Academic's Markdown slides feature.   Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/). -- ","date":1062374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1062374400,"objectID":"549c824f275eadcae1f813425a3c32fe","permalink":"/publication/icml-process-induction/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/icml-process-induction/","section":"publication","summary":"In this paper, we revisit the problem of in- ducing a process modelfrom time-series data. Weillustrate this task with a realistic ecosys- tem model, review an initial method for its induction, then identify three challenges that require extension of this method. These in- clude dealing with unobservable variables, finding numeric conditions on processes, and preventing the creation of models that over- fit the training data. Wedescribe responses to these challenges and present experimental evidence that they have the desired effects. After this, we show that this extended ap- proach to inductive process modeling can ex- plain and predict time-series data from bat- teries on the International Space Station. In closing, we discuss related work and consider directions for future research.","tags":["Source Themes"],"title":"Robust induction of process models from time-series data","type":"publication"},{"authors":null,"categories":null,"content":"  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"e0804cb8dffb93ff9841c7ca826f0e3e","permalink":"/talks/brain2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/talks/brain2/","section":"talks","summary":"  ","tags":null,"title":"Brain Inspired. Podcast with Paul Middlebrooks. Episode 93. Infernce in Brain Micorcircuits","type":"talks"}]